{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EL5Fp3i3h_o"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyvvVvqxPR9B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pydot\n",
    "import graphviz\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers import AveragePooling2D, Flatten, Dense, Dropout, Input\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "import tensorflow\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpK07xOAPWnP"
   },
   "outputs": [],
   "source": [
    "# Set the path to your dataset folder in Google Drive\n",
    "dataset_path = '/content/drive/MyDrive/Video_Project/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IC1CkPiPtXq"
   },
   "outputs": [],
   "source": [
    "# Initialize the labels and data lists\n",
    "LABELS = []\n",
    "data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Processing images from subfolders in a specified directory and stores the processed images and their class labels in lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ZwjdpA-PwuC",
    "outputId": "c50a8a25-8424-4abc-9790-48b3da819969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shooting\n",
      "wrestling\n",
      "table_tennis\n",
      "volleyball\n",
      "swimming\n",
      "wwe\n",
      "motogp\n",
      "weight_lifting\n",
      "tennis\n",
      "fencing\n",
      "kabaddi\n",
      "gymnastics\n",
      "boxing\n",
      "hockey\n",
      "football\n",
      "ice_hockey\n",
      "cricket\n",
      "formula1\n",
      "chess\n",
      "baseball\n",
      "badminton\n",
      "basketball\n"
     ]
    }
   ],
   "source": [
    "# Loop over the subfolders\n",
    "for class_folder in os.listdir(dataset_path):\n",
    "    print(class_folder)\n",
    "    class_folder_path = os.path.join(dataset_path, class_folder)\n",
    "    if os.path.isdir(class_folder_path):\n",
    "        # Loop over the images in the subfolder\n",
    "        for image_file in os.listdir(class_folder_path):\n",
    "            if image_file.endswith((\".gif\", \".aspx\", \".ipynb_checkpoints\")):  # Skip images with \".gif\", \".aspx\", \".ipynb_checkpoints\" extension\n",
    "                continue\n",
    "            image_path = os.path.join(class_folder_path, image_file)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (224, 224))\n",
    "            data.append(image)\n",
    "            LABELS.append(class_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8M6FM91uhgr",
    "outputId": "7437941f-15cc-4346-c1ed-f4cea1aa6764"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14512"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fOwUchhBuhXL",
    "outputId": "cc62d092-e092-4b1e-a73d-bbad4b575f13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14512"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uYzNaOKbm15"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/content/drive/MyDrive/Video_Project/data.pickle', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "with open('/content/drive/MyDrive/Video_Project/labels.pickle', 'wb') as f:\n",
    "    pickle.dump(LABELS, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lc82wWkbcG3p"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load data from the pickle file\n",
    "with open('/content/drive/MyDrive/Video_Project/data.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Load LABELS from the pickle file\n",
    "with open('/content/drive/MyDrive/Video_Project/labels.pickle', 'rb') as f:\n",
    "    LABELS = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z1B3rMJGcLWm"
   },
   "outputs": [],
   "source": [
    "# Convert data and labels to NumPy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SSF5ytiyV_JN"
   },
   "outputs": [],
   "source": [
    "# Perform label binarization\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-F7EUElnWCq3"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('labelBinarizer.pickle', 'wb') as f:\n",
    "    pickle.dump(lb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SF5BniWnu5jP"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/content/drive/MyDrive/Video_Project/data_np.pickle', 'wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "with open('/content/drive/MyDrive/Video_Project/labels_np.pickle', 'wb') as f:\n",
    "    pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTk2PGMbu5bQ"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load data from the pickle file\n",
    "with open('/content/drive/MyDrive/Video_Project/data_np.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Load labels from the pickle file\n",
    "with open('/content/drive/MyDrive/Video_Project/labels_np.pickle', 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data into tain and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partition the data into training and testing sets\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXhiE4P0cjlY"
   },
   "outputs": [],
   "source": [
    "print(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZeJaoeYzdwjs",
    "outputId": "1dbf6d1e-913a-4987-f2f5-b1cad838fc0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n",
      "(14512, 22)\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mqVq5ETziOG"
   },
   "outputs": [],
   "source": [
    "# Initialize the training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "# Initialize the validation/testing data augmentation object\n",
    "valAug = ImageDataGenerator()\n",
    "\n",
    "# Define the ImageNet mean subtraction (in RGB order) and set the mean subtraction value for each of the data augmentation objects\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a neural network model using the ResNet-50 architecture and setting the layers in the 'conv5_' group to be trainable for fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JARXdYRUvq5",
    "outputId": "98381d54-b646-45d3-a131-51edac335f66",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the ResNet-50 network, excluding the head FC layers\n",
    "baseModel = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# Construct the head of the model to be placed on top of the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(2048, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.2)(headModel)\n",
    "headModel = Dense(1024, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(22, activation=\"softmax\")(headModel)\n",
    "\n",
    "# Place the head FC model on top of the base model\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for basemodelLayers in baseModel.layers:\n",
    "    if basemodelLayers.name.startswith('conv5_'):\n",
    "        basemodelLayers.trainable = True\n",
    "    else:\n",
    "        basemodelLayers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktJto5kN1KIc"
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MHADnaYfU6KQ",
    "outputId": "7c1dd420-5a45-4e52-9f1e-5c071ae51a74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training the head...\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "# opt = SGD(learning_rate=1e-4, momentum=0.9, decay=1e-4 / 50)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the head of the network for a few epochs\n",
    "print(\"[INFO] Training the head...\")\n",
    "H = model.fit(\n",
    "    x=trainAug.flow(X_train, y_train, batch_size=32),\n",
    "    steps_per_epoch=len(X_train) // 32,\n",
    "    validation_data=valAug.flow(X_test, y_test),\n",
    "    validation_steps=len(X_test) // 32,\n",
    "    epochs=50)\n",
    "\n",
    "model.save(\"model_after_50_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPN8hkj7XUO1"
   },
   "outputs": [],
   "source": [
    "model = tensorflow.keras.models.load_model(\"model_after_50_epochs\")\n",
    "with open('labelBinarizer.pickle', 'rb') as f:\n",
    "    lb = pickle.load(f)\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "Queue = deque(maxlen = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing a video file, makes real-time predictions using a deep learning model, and annotates the video frames with activity labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1YstVEkr28Yz"
   },
   "outputs": [],
   "source": [
    "capture_video = cv2.VideoCapture(\"boxing.mp4\")\n",
    "writer = None\n",
    "(Width, Height) = (None, None)\n",
    "while True:\n",
    "    (taken, frame) = capture_video.read()\n",
    "    if not taken:\n",
    "        break\n",
    "    if Width is None or Height is None:\n",
    "        (Width, Height) = frame.shape[:2]\n",
    "\n",
    "    output = frame.copy()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (224, 224)).astype(\"float32\")\n",
    "    frame -= mean\n",
    "    preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "    Queue.append(preds)\n",
    "    results = np.array(Queue).mean(axis = 0)\n",
    "    i = np.argmax(results)\n",
    "    label = lb.classes_[i]\n",
    "    text = \"They are playing : {}\".format(label)\n",
    "    cv2.putText(output,text, (45, 60), cv2.FONT_HERSHEY_SIMPLEX,1.25, (255,0,0), 5)\n",
    "\n",
    "    if writer is None:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv2.VideoWriter(\"outputvideo\", fourcc, 30, (Width, Height), True)\n",
    "    writer.write(output)\n",
    "    cv2.imshow(\"In progress\", output)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "print(\"Finalizing....\")\n",
    "writer.release()\n",
    "capture_video.release()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
